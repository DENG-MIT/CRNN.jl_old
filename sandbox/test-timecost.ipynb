{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DiffEqFlux, OrdinaryDiffEq, Flux, Optim, Plots\n",
    "\n",
    "using Flux: gradient\n",
    "using Flux.Optimise: update!\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 10\n",
    "n_epoch = 100000\n",
    "n_exp = 30\n",
    "\n",
    "function trueODEfunc(dydt, y, k, t)\n",
    "    dydt[1] = -2 * k[1] * y[1]^2 - k[2] * y[1]\n",
    "    dydt[2] = k[1] * y[1]^2 - k[4] * y[2] * y[4]\n",
    "    dydt[3] = k[2] * y[1] - k[3] * y[3]\n",
    "    dydt[4] = k[3] * y[3] - k[4] * y[2] * y[4]\n",
    "    dydt[5] = k[4] * y[2] * y[4]\n",
    "end\n",
    "\n",
    "ns = 5\n",
    "nr = 4\n",
    "u0_list = rand(Float32, (n_exp, ns))\n",
    "u0_list[:, 3:ns] .= 0\n",
    "\n",
    "datasize = 20\n",
    "tspan = Float32[0.0, 20.0]\n",
    "tsteps = range(tspan[1], tspan[2], length = datasize)\n",
    "k = Float32[0.1, 0.2, 0.13, 0.3]\n",
    "alg = Rosenbrock23(autodiff = false)\n",
    "\n",
    "ode_data_list = []\n",
    "\n",
    "for i in 1:n_exp\n",
    "    u0 = u0_list[i, :]\n",
    "    prob_trueode = ODEProblem(trueODEfunc, u0, tspan, k)\n",
    "    ode_data = Array(solve(prob_trueode, alg, saveat = tsteps))\n",
    "    push!(ode_data_list, ode_data)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 1e-5\n",
    "ub = 10.0\n",
    "\n",
    "dudt2 = FastChain((x, p)->log.(clamp.(x, lb, ub)),\n",
    "                  FastDense(5, 4, exp),\n",
    "                  FastDense(4, 5))\n",
    "\n",
    "prob_neuralode = NeuralODE(dudt2, tspan, alg, saveat = tsteps)\n",
    "p = prob_neuralode.p\n",
    "\n",
    "function clip_p(p)\n",
    "    # layer1: 5x4+4 = 24\n",
    "    # layer2: 4x5+5 = 25\n",
    "    p[1:20] .= clamp.(p[1:20], 0, 2.5)\n",
    "    p[45:49] .= 0\n",
    "\n",
    "    return p\n",
    "end\n",
    "\n",
    "\n",
    "function set_p(p)\n",
    "    p = zeros(49)\n",
    "    p[1:4] = [2,1,0,0]\n",
    "    p[5:8] = [0,0,0,1]\n",
    "    p[9:12] = [0,0,1,0]\n",
    "    p[13:16] = [0,0,0,1]\n",
    "    p[17:20] = [0,0,0,0]\n",
    "\n",
    "    p[21:24] .= log.([0.1, 0.2, 0.13, 0.3])\n",
    "\n",
    "    p[25:29] .= [-2,  1,  0,  0, 0]\n",
    "    p[30:34] .= [-1,  0,  1,  0, 0]\n",
    "    p[35:39] .= [ 0,  0, -1,  1, 0]\n",
    "    p[40:44] .= [ 0, -1,  0, -1, 1]\n",
    "    return p\n",
    "end\n",
    "\n",
    "\n",
    "function predict_neuralode(u0, p)\n",
    "    pred = clamp.(Array(prob_neuralode(u0, p)), -ub, ub)\n",
    "    return pred\n",
    "end\n",
    "\n",
    "function loss_neuralode(p, i_exp)\n",
    "    u0 = u0_list[i_exp, :]\n",
    "    ode_data = ode_data_list[i_exp]\n",
    "    pred = predict_neuralode(u0, p)\n",
    "    loss = sum(abs2, ode_data .- pred)\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function loss_pred_neuralode(p, i_exp)\n",
    "    u0 = u0_list[i_exp, :]\n",
    "    ode_data = ode_data_list[i_exp]\n",
    "    pred = predict_neuralode(u0, p)\n",
    "    loss = sum(abs2, ode_data .- pred)\n",
    "    return loss, pred\n",
    "end\n",
    "\n",
    "function display_p(p)\n",
    "    println(\"s1\")\n",
    "    println(p[1:4])\n",
    "    println(\"s2\")\n",
    "    println(p[5:8])\n",
    "    println(\"s3\")\n",
    "    println(p[9:12])\n",
    "    println(\"s4\")\n",
    "    println(p[13:16])\n",
    "    println(\"s5\")\n",
    "    println(p[17:20])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback function to observe training\n",
    "\n",
    "cbi = function (p, i_exp)\n",
    "\n",
    "    ode_data = ode_data_list[i_exp]\n",
    "    pred = predict_neuralode(u0_list[i_exp, :], p)\n",
    "    list_plt = []\n",
    "    for i in 1:ns\n",
    "        plt = scatter(tsteps, ode_data[i,:], title = string(i), label = string(\"data_\",i))\n",
    "        plot!(plt, tsteps, pred[i,:], label = string(\"pred_\",i))\n",
    "        push!(list_plt, plt)\n",
    "    end\n",
    "    plt_all = plot(list_plt..., legend = false)\n",
    "    png(plt_all, string(\"figs/i_exp_\", i_exp))\n",
    "    return false\n",
    "end\n",
    "\n",
    "list_loss = []\n",
    "iter = 0\n",
    "cb = function (p, loss_mean)\n",
    "    global list_loss, iter\n",
    "    push!(list_loss, loss_mean)\n",
    "    println(string(\"\\n\", \"iter = \", iter, \" loss = \", loss_mean, \"\\n\"))\n",
    "\n",
    "    if iter % n_plot == 0\n",
    "        display_p(p)\n",
    "\n",
    "        for i_exp in [1, 10, 20, 30]\n",
    "            cbi(p, i_exp)\n",
    "        end\n",
    "\n",
    "        if iter < 2000\n",
    "            plt_loss = plot(list_loss, yscale = :log10, label=\"loss\")\n",
    "        else\n",
    "            plt_loss = plot(list_loss, xscale = :log10, yscale = :log10, label=\"loss\")\n",
    "        end\n",
    "        png(plt_loss, \"figs/loss\")\n",
    "    end\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "end\n",
    "\n",
    "opt = ADAM(0.001)\n",
    "\n",
    "p = clip_p(p)\n",
    "\n",
    "loss_all = zeros(Float32, n_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"haha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
